---
title: "Larg m"
format: docx
---

```{r, echo=F, warning=F, message=F}
library(tidyverse)
library(gt)
library(tidybayes)

source("../lib/fmt_APA.R")
source("../lib/mcmc.R")
load("../data/export/paper_large_model.Rdata")

# samples as matrix
llm <- as.matrix(larg_mod_test)
loL <- brms::loo(larg_mod_test)$estimates["looic",]

coef_hdi <- function(x){
  dir="+"
  m <- mean(x)
  ll <- hdi(x)[1]
  ul <- hdi(x)[2]
  erat <- sum(x>0)/sum(x<=0)
  pval <- sum(x>0)/length(x)

  if(m<0){
    erat=1./erat
    pval=1-pval
    dir="-"
  }
  # pval=sprintf("%.2f",pval)
  if(is.infinite(erat)){
    erat=ifelse(erat<0, "-\\infty", "\\infty")
  } else {
    erat=fmt_APA_numbers(erat)
  }
  sprintf("$b=%s, [%s, %s], p^{%s}=%s, \\text{ER}^{%s}=%s$", 
          fmt_APA_numbers(m), 
          fmt_APA_numbers(ll), 
          fmt_APA_numbers(ul), 
          dir, 
          fmt_APA_numbers(pval, .p=T),
          dir, 
          erat
          )
}
```

<!---    Describe big analysis that is placed in the supplemental material    --->

We conducted an exploratory Bayesian analysis to determine the relationship between AE, BV and MW. We used an ordered-probit model, treating the ordinal MW variable as the outcome variable and including the behavioural indices behavioural variability and approximate entropy along with block, stimulation condition and all relevant interactions but for the AE $\times$ BV interaction (see Table S8 for all coefficients). Also in this model, we found that real stimulation seemed to increased MW (B1 $\times$ stimulation: `r coef_hdi(llm[,"b_stimulationreal:blockB1"])`; B2 $\times$ stimulation: `r coef_hdi(llm[,"b_stimulationreal:blockB2"])`; B3 $\times$ stimulation: `r coef_hdi(llm[,"b_stimulationreal:blockB3"])`), compared to sham stimulation (B1: `r coef_hdi(llm[,"b_blockB1"])`; B2: `r coef_hdi(llm[,"b_blockB2"])`; B3: `r coef_hdi(llm[,"b_blockB3"])`). Intriguingly, we found that real stimulation interacted with BV during the last two blocks (BV $\times$ B2 $\times$ stimulation: `r coef_hdi(llm[,"b_stimulationreal:blockB2:zlogbv"])`; BV $\times$ B3 $\times$ stimulation: `r coef_hdi(llm[,"b_stimulationreal:blockB3:zlogbv"])`), such that BV no longer predicted MW. As for AE, even though it negatively predicted MW (AE: `r coef_hdi(llm[,"b_zlogapen"])`), over time, this negative prediction dissipated for both the sham stimulation (AE $\times$ B1: `r coef_hdi(llm[,"b_zlogapen:blockB1"])`; AE $\times$ B2: `r coef_hdi(llm[,"b_zlogapen:blockB2"])`; AE $\times$ B3: `r coef_hdi(llm[,"b_zlogapen:blockB3"])`) and the real  stimulation (AE $\times$ stimulation: `r coef_hdi(llm[,"b_zlogapen:stimulationreal"])`; AE $\times$ B1 $\times$ stimulation: `r coef_hdi(llm[,"b_zlogapen:stimulationreal:blockB1"])`; AE $\times$ B2 $\times$ stimulation: `r coef_hdi(llm[,"b_zlogapen:stimulationreal:blockB2"])`; AE $\times$ B3 $\times$ stimulation: `r coef_hdi(llm[,"b_zlogapen:stimulationreal:blockB3"])`). 



```{r quick vis, include=FALSE}
#colnames(llm)
as_tibble(llm) |>
  pivot_longer(c("b_blockB1:zlogbv","b_blockB2:zlogbv","b_blockB3:zlogbv")) |>
  ggplot(aes(name, value)) +
  stat_summary(fun.data = mean_se)

as_tibble(llm) |>
  pivot_longer(c("b_stimulationreal:blockB1:zlogbv","b_stimulationreal:blockB2:zlogbv","b_stimulationreal:blockB3:zlogbv")) |>
  ggplot(aes(name, value)) +
  stat_summary(fun.data = mean_se)
```



```{r visualize the (absolute) prediction AE and BV have on MW, echo=FALSE}
#| fig-width: 6
#| fig-height: 3
#| fig-dpi: 400
as_tibble(llm) |>
  mutate(
    B0_BV_sham = b_zlogbv,
    B0_BV_real = `b_stimulationreal:zlogbv`,
    B1_BV_sham = b_zlogbv+`b_blockB1:zlogbv`,
    B1_BV_real =`b_stimulationreal:zlogbv`+ `b_blockB1:zlogbv` + `b_stimulationreal:blockB1:zlogbv`,
    B2_BV_sham = b_zlogbv+`b_blockB2:zlogbv`,
    B2_BV_real = `b_stimulationreal:zlogbv`+`b_blockB2:zlogbv` + `b_stimulationreal:blockB2:zlogbv`,
    B3_BV_sham = b_zlogbv+`b_blockB3:zlogbv`,
    B3_BV_real = `b_stimulationreal:zlogbv`+`b_blockB3:zlogbv` + `b_stimulationreal:blockB3:zlogbv`,
    B0_AE_sham = b_zlogapen,
    B0_AE_real = `b_zlogapen:stimulationreal`,
    B1_AE_sham = b_zlogapen+`b_zlogapen:blockB1`,
    B1_AE_real =`b_zlogapen:stimulationreal`+`b_zlogapen:blockB1` + `b_zlogapen:stimulationreal:blockB1`,
    B2_AE_sham = b_zlogapen+`b_zlogapen:blockB2`,
    B2_AE_real = `b_zlogapen:stimulationreal`+`b_zlogapen:blockB2` + `b_zlogapen:stimulationreal:blockB2`,
    B3_AE_sham = b_zlogapen+`b_zlogapen:blockB3`,
    B3_AE_real = `b_zlogapen:stimulationreal`+`b_zlogapen:blockB3` + `b_zlogapen:stimulationreal:blockB3`,
  ) |>
  select(starts_with("B", ignore.case=F)) |>
  pivot_longer( everything() ) |>
  separate_wider_delim(name, delim = "_", names = c("block","var", "stimulation")) |>
  mutate(stimulation = factor( stimulation, levels = c("sham", "real"))) |>
  ggplot(aes( x = block, y = value, color = stimulation )) +
  geom_hline(yintercept=0, linetype = "dashed") + 
  facet_wrap(~var) +
  stat_summary(fun = mean, geom="line", aes(group=stimulation), position=position_dodge(width=0.2)) +
  stat_summary(fun.data = mean_hdci, geom="pointrange", position=position_dodge(width=0.2)) +
    # mean_hdci might not be the same as hdi (but it seems to be the same...)
  labs(y = "MW", x = "Block") + 
  scale_y_continuous(breaks=seq(-1,1,.1)) +
  theme_bw()

#' AE's prediction changes over time (from being a significant negative predictor of MW to a non-significant?) 
#' not sure if I want to argue for "more stability" thought, just a disconnect of the "dynamic". 

```


```{r visualize the (relative) prediction AE and BV have on MW, echo=FALSE}
#| fig-width: 6
#| fig-height: 3
#| fig-dpi: 400
as_tibble(llm) |>
  mutate(
    B0_BV_sham = 0,
    B0_BV_real = 0,
    B1_BV_sham = `b_blockB1:zlogbv`,
    B1_BV_real = `b_blockB1:zlogbv` + `b_stimulationreal:blockB1:zlogbv`,
    B2_BV_sham = `b_blockB2:zlogbv`,
    B2_BV_real = `b_blockB2:zlogbv` + `b_stimulationreal:blockB2:zlogbv`,
    B3_BV_sham = `b_blockB3:zlogbv`,
    B3_BV_real = `b_blockB3:zlogbv` + `b_stimulationreal:blockB3:zlogbv`,
    B0_AE_sham = 0,
    B0_AE_real = 0,
    B1_AE_sham = `b_zlogapen:blockB1`,
    B1_AE_real = `b_zlogapen:blockB1` + `b_zlogapen:stimulationreal:blockB1`,
    B2_AE_sham = `b_zlogapen:blockB2`,
    B2_AE_real = `b_zlogapen:blockB2` + `b_zlogapen:stimulationreal:blockB2`,
    B3_AE_sham = `b_zlogapen:blockB3`,
    B3_AE_real = `b_zlogapen:blockB3` + `b_zlogapen:stimulationreal:blockB3`,
  ) |>
  select(starts_with("B", ignore.case=F)) |>
  pivot_longer( everything() ) |>
  separate_wider_delim(name, delim = "_", names = c("block","var", "stimulation")) |>
  mutate(stimulation = factor( stimulation, levels = c("sham", "real"))) |>
  ggplot(aes( x = block, y = value, color = stimulation )) +
  geom_hline(yintercept=0, linetype = "dashed") + 
  facet_wrap(~var) +
  stat_summary(fun = mean, geom="line", aes(group=stimulation), position=position_dodge(width=0.2)) +
  stat_summary(fun.data = mean_hdci, geom="pointrange", position=position_dodge(width=0.2)) +
    # mean_hdci might not be the same as hdi (but it seems to be the same...)
  labs(y = "MW", x = "Block") + 
  scale_y_continuous(breaks=seq(-1,1,.1)) +
  theme_bw()

```



```{r visualize the (marginal), echo=FALSE}
#| fig-width: 6
#| fig-height: 3
#| fig-dpi: 400
as_tibble(llm) |>
  mutate(
    B0_BV_diff = 0,
    B1_BV_diff = `b_stimulationreal:blockB1:zlogbv` - `b_blockB1:zlogbv`,
    B2_BV_diff = `b_stimulationreal:blockB2:zlogbv` - `b_blockB2:zlogbv`,
    B3_BV_diff = `b_stimulationreal:blockB3:zlogbv` - `b_blockB3:zlogbv`,
    B0_AE_diff = 0,
    B1_AE_diff = `b_zlogapen:stimulationreal:blockB1` - `b_zlogapen:blockB1`,
    B2_AE_diff = `b_zlogapen:stimulationreal:blockB2` - `b_zlogapen:blockB2`,
    B3_AE_diff = `b_zlogapen:stimulationreal:blockB3` - `b_zlogapen:blockB3`,
  ) |>
  select(starts_with("B", ignore.case=F)) |>
  pivot_longer( everything() ) |>
  separate_wider_delim(name, delim = "_", names = c("block","var", "stimulation")) |>
  mutate(stimulation = factor( stimulation, levels = c("sham", "real"))) |>
  ggplot(aes( x = block, y = value )) +
  facet_wrap(~var) +
  geom_hline(yintercept=0, linetype = "dashed") +
  stat_summary(fun = mean, geom="line", position=position_dodge(width=0.2)) +
  stat_summary(fun.data = mean_hdci, geom="pointrange") +
    # mean_hdci might not be the same as hdi (but it seems to be the same...)
  labs(y = "MW", x = "Block")+ 
  theme_bw()

```